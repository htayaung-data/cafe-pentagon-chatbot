"""
Response Generator Node for LangGraph
Generates contextual responses based on retrieved documents and user intent
Enhanced with sophisticated Burmese handling from previous implementation
"""

from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from src.utils.logger import get_logger
from src.config.settings import get_settings
from src.services.semantic_context_extractor import get_semantic_context_extractor

logger = get_logger("response_generator_node")


class ResponseGeneratorNode:
    """
    LangGraph node for response generation
    Generates contextual responses based on RAG results and user intent
    Enhanced with sophisticated Burmese handling
    """
    
    def __init__(self):
        """Initialize response generator node"""
        self.settings = get_settings()
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.7,
            api_key=self.settings.openai_api_key
        )
        self.semantic_extractor = get_semantic_context_extractor()
        logger.info("response_generator_node_initialized")
    
    async def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate contextual response based on analysis results and routing decisions
        Enhanced for two-LLM-call architecture with better Burmese support
        
        Args:
            state: Current conversation state with analysis and routing results
            
        Returns:
            Updated state with generated response and HITL metadata
        """
        user_message = state.get("user_message", "")
        analysis_result = state.get("analysis_result", {})
        routing_decision = state.get("routing_decision", {})
        rag_results = state.get("rag_results", [])
        
        # Extract information from analysis result
        detected_language = analysis_result.get("detected_language", "en")
        primary_intent = analysis_result.get("primary_intent", "unknown")
        intent_confidence = analysis_result.get("intent_confidence", 0.0)
        cultural_context = analysis_result.get("cultural_context", {})
        conversation_context = analysis_result.get("conversation_context", {})
        
        # Extract information from routing decision
        action_type = routing_decision.get("action_type", "perform_search")
        rag_enabled = routing_decision.get("rag_enabled", True)
        human_handling = routing_decision.get("human_handling", False)
        escalation_reason = routing_decision.get("escalation_reason")
        decision_confidence = routing_decision.get("confidence", 0.5)
        
        # Human assistance is determined by routing decision only - no pattern matching
        requires_human = human_handling
        
        try:
            # Handle different action types based on routing decision
            if action_type == "escalate_to_human":
                response = await self._generate_escalation_response(detected_language, escalation_reason)
            elif action_type == "direct_response":
                if primary_intent == "greeting":
                    response = await self._generate_greeting_response(detected_language, cultural_context)
                elif primary_intent == "goodbye":
                    response = await self._generate_goodbye_response(detected_language, cultural_context)
                else:
                    response = await self._generate_direct_response(user_message, detected_language, primary_intent, cultural_context)
            elif action_type == "perform_search" and rag_enabled:
                if detected_language == "my":
                    # Use enhanced Burmese handling with conversation history
                    conversation_history = state.get("conversation_history", [])
                    response = await self._generate_enhanced_burmese_response(
                            user_message, primary_intent, rag_results, cultural_context, conversation_context
                    )
                else:
                    # Generate contextual response based on RAG results
                    response = await self._generate_contextual_response(
                            user_message, detected_language, primary_intent, rag_results, cultural_context
                    )
            else:
                # Fallback for unknown action types
                response = await self._generate_fallback_response(user_message, detected_language, primary_intent, cultural_context)
            
            # Log response generation
            logger.info("response_generated",
                       intent=primary_intent,
                       language=detected_language,
                       action_type=action_type,
                       intent_confidence=intent_confidence,
                       decision_confidence=decision_confidence,
                       response_length=len(response),
                       has_rag_results=bool(rag_results),
                       rag_enabled=rag_enabled,
                       requires_human=requires_human,
                       human_handling=human_handling)
            
            # Update state with generated response and HITL metadata
            updated_state = state.copy()
            updated_state.update({
                "response": response,
                "response_generated": True,
                "response_quality": self._assess_response_quality(response, intent_confidence, decision_confidence),
                "requires_human": requires_human,
                "human_handling": human_handling,
                "escalation_reason": escalation_reason,
                "action_type": action_type,
                "rag_enabled": rag_enabled
            })
            
            return updated_state
            
        except Exception as e:
            logger.error("response_generation_failed",
                        error=str(e),
                        user_message=user_message[:100])
            
            # Generate fallback response on error
            fallback_response = await self._generate_fallback_response(user_message, detected_language, primary_intent, cultural_context)
            
            updated_state = state.copy()
            updated_state.update({
                "response": fallback_response,
                "response_generated": True,
                "response_quality": "fallback",
                "requires_human": requires_human,
                "human_handling": human_handling,
                "escalation_reason": escalation_reason,
                "action_type": action_type,
                "rag_enabled": rag_enabled
            })
            
            return updated_state
    
    async def _generate_enhanced_burmese_response(self, user_message: str, intent: str, rag_results: List[Dict[str, Any]], cultural_context: Dict[str, Any], conversation_context: Dict[str, Any]) -> str:
        """
        Enhanced Burmese response generation with menu-specific handling
        (Extracted from burmese_customer_services_handler.py)
        """
        try:
            # Check if this is a menu-related query that needs special handling
            if intent == "menu_browse":
                # Handle menu-specific responses
                relevance_score = rag_results[0].get("score", 0.5) if rag_results else 0.0
                return await self._handle_burmese_menu_response(user_message, rag_results, relevance_score)
            
            # Check if we have relevant data
            has_relevant_data = len(rag_results) > 0
            
            if has_relevant_data:
                # Use RAG results to generate contextual response
                context = self._prepare_rag_context(rag_results)
                
                # Log the actual data being used
                logger.info("using_rag_data_for_response",
                           rag_results_count=len(rag_results),
                           context_preview=context[:200])
                
                # Create a prompt that uses the actual Burmese content directly
                prompt = f"""
You are a helpful restaurant chatbot assistant for Cafe Pentagon. Generate a response in Burmese based on the user's question.

USER QUESTION: {user_message}

ACTUAL DATA FROM DATABASE (Use Burmese content directly):
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Use ONLY the actual data provided above
- If the data shows Burmese content (question_mm, answer_mm, myanmar_name, description_mm), use it directly
- Do NOT translate or invent any information not present in the data
- Be friendly and helpful
- Keep the response conversational and natural
- If the data is incomplete, suggest calling +959979732781

IMPORTANT: Use the Burmese content directly from the data. Do not translate or invent information.

RESPONSE:"""
                
                from langchain_core.messages import HumanMessage
                response = self.llm.invoke([HumanMessage(content=prompt)])
                return response.content.strip()
            else:
                # No relevant data found - use sophisticated fallback like the working implementation
                logger.info("no_relevant_rag_data_found", 
                           rag_results_count=len(rag_results))
                return await self._generate_enhanced_burmese_fallback(user_message)
                
        except Exception as e:
            logger.error("enhanced_burmese_response_failed", error=str(e))
            return await self._generate_enhanced_burmese_fallback(user_message)
    
    async def _generate_enhanced_burmese_fallback(self, user_message: str) -> str:
        """Generate sophisticated Burmese fallback response with specific answers for common queries"""
        try:
            # Check for specific common queries and provide direct answers
            user_lower = user_message.lower()
            
            # Location queries
            if any(keyword in user_lower for keyword in ["á€˜á€šá€ºá€™á€¾á€¬", "á€á€Šá€ºá€”á€±á€›á€¬", "á€œá€­á€•á€ºá€…á€¬", "address", "location", "where"]):
                return """á€¡á€™á€¾á€á€º á‚áˆá…áŠ á€™á€Ÿá€¬á€—á€”á€¹á€“á€¯á€œá€œá€™á€ºá€¸áŠ áƒá‰ á€›á€•á€ºá€€á€½á€€á€ºáŠ á€™á€¼á€±á€¬á€€á€ºá€’á€‚á€¯á€¶á€™á€¼á€­á€¯á€·á€”á€šá€ºáŠ á€›á€”á€ºá€€á€¯á€”á€ºá€™á€¾á€¬ á€á€Šá€ºá€›á€¾á€­á€•á€«á€á€šá€ºá‹ 

Google Map Link: https://maps.app.goo.gl/G5aFQDUkuW4RuTKe9

á€•á€­á€¯á€™á€­á€¯á€á€­á€›á€¾á€­á€œá€­á€¯á€•á€«á€€ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"""
            
            # Hours queries
            elif any(keyword in user_lower for keyword in ["á€˜á€šá€ºá€¡á€á€»á€­á€”á€º", "á€•á€­á€á€ºá€á€»á€­á€”á€º", "á€–á€½á€„á€·á€ºá€á€»á€­á€”á€º", "opening", "closing", "hours"]):
                return """á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€€ á‰ á€”á€¬á€›á€®á€€á€”á€± áá€ á€”á€¬á€›á€®á€¡á€‘á€­ á€”á€±á€·á€…á€‰á€ºá€–á€½á€„á€·á€ºá€•á€«á€á€šá€ºá‹ áá€ á€”á€¬á€›á€®á€™á€¾á€¬á€•á€­á€á€ºá€•á€«á€á€šá€ºá‹

á€”á€±á€¬á€€á€ºá€‘á€•á€ºá€™á€±á€¸á€™á€¼á€”á€ºá€¸á€›á€”á€ºá€›á€¾á€­á€œá€»á€¾á€„á€º á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€•á€«á‹"""
            
            # Photo queries
            elif any(keyword in user_lower for keyword in ["á€“á€«á€á€ºá€•á€¯á€¶", "á€›á€­á€¯á€€á€ºá€€á€°á€¸", "photo", "photography"]):
                return """á€“á€«á€á€ºá€•á€¯á€¶á€›á€­á€¯á€€á€ºá€€á€°á€¸á€á€½á€„á€·á€ºá€›á€¾á€­á€•á€«á€á€šá€ºá‹ á€á€­á€¯á€·á€á€±á€¬á€º Professional Camera á€™á€»á€¬á€¸á€¡á€á€½á€€á€º á€á€½á€„á€·á€ºá€•á€¼á€¯á€á€»á€€á€ºá€œá€­á€¯á€¡á€•á€ºá€•á€«á€á€šá€ºá‹

Mobile Phone á€–á€¼á€„á€·á€ºá€›á€­á€¯á€€á€ºá€€á€°á€¸á€á€¼á€„á€ºá€¸á€€á€­á€¯ á€á€½á€„á€·á€ºá€•á€¼á€¯á€‘á€¬á€¸á€•á€«á€á€šá€ºá‹

á€•á€­á€¯á€™á€­á€¯á€á€­á€›á€¾á€­á€œá€­á€¯á€•á€«á€€ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"""
            
            # Menu queries
            elif any(keyword in user_lower for keyword in ["á€˜á€¬", "á€¡á€…á€¬á€¸á€¡á€…á€¬", "menu", "food", "dish"]):
                return """á€€á€»á€”á€±á€¬á€ºá€á€­á€¯á€·á€›á€²á€· á€™á€®á€”á€°á€¸á€™á€¾á€¬ á€’á€®á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€á€½á€± á€›á€¾á€­á€•á€«á€á€šá€º:

â€¢ **á€á€±á€«á€€á€ºá€†á€½á€²**
â€¢ **á€†á€œá€•á€º**
â€¢ **á€‘á€™á€„á€ºá€¸á€Ÿá€„á€ºá€¸**
â€¢ **á€”á€¶á€”á€€á€ºá€…á€¬**
â€¢ **á€•á€«á€…á€á€¬**
â€¢ **á€Ÿá€„á€ºá€¸á€›á€Šá€º**
â€¢ **á€¡á€“á€­á€€á€Ÿá€„á€ºá€¸**
â€¢ **á€¡á€›á€¶á€Ÿá€„á€ºá€¸**
â€¢ **á€¡á€á€¬á€¸á€Šá€¾á€•á€º á€”á€¾á€„á€·á€º á€˜á€¬á€‚á€«**

á€˜á€šá€ºá€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€€á€­á€¯ á€€á€¼á€Šá€·á€ºá€á€»á€„á€ºá€•á€«á€á€œá€²?"""
            
            # Contact queries
            elif any(keyword in user_lower for keyword in ["á€–á€¯á€”á€ºá€¸", "á€†á€€á€ºá€á€½á€šá€º", "phone", "contact", "call"]):
                return """á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€›á€”á€º:

ğŸ“ Phone: +959979732781
ğŸ“ Address: á€¡á€™á€¾á€á€º á‚áˆá…áŠ á€™á€Ÿá€¬á€—á€”á€¹á€“á€¯á€œá€œá€™á€ºá€¸áŠ áƒá‰ á€›á€•á€ºá€€á€½á€€á€ºáŠ á€™á€¼á€±á€¬á€€á€ºá€’á€‚á€¯á€¶á€™á€¼á€­á€¯á€·á€”á€šá€ºáŠ á€›á€”á€ºá€€á€¯á€”á€º

á€¡á€á€±á€¸á€…á€­á€á€ºá€á€­á€›á€¾á€­á€œá€­á€¯á€•á€«á€€ á€–á€¯á€”á€ºá€¸á€†á€€á€ºá€á€½á€šá€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"""
            
            # Delivery queries
            elif any(keyword in user_lower for keyword in ["á€•á€­á€¯á€·á€•á€±á€¸á€™á€¾á€¯", "delivery", "á€•á€­á€¯á€·á€†á€±á€¬á€„á€ºá€™á€¾á€¯"]):
                return """á€•á€­á€¯á€·á€†á€±á€¬á€„á€ºá€™á€¾á€¯á€á€”á€ºá€†á€±á€¬á€„á€ºá€™á€¾á€¯á€›á€¾á€­á€•á€«á€á€šá€ºá‹ 

á€•á€­á€¯á€·á€†á€±á€¬á€„á€ºá€™á€¾á€¯á€¡á€á€½á€€á€º +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€•á€«á‹

á€•á€­á€¯á€·á€†á€±á€¬á€„á€ºá€á€™á€¾á€¬ á€¡á€€á€½á€¬á€¡á€á€±á€¸á€•á€±á€«á€ºá€™á€°á€á€Šá€ºá€•á€¼á€®á€¸ á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"""
            
            # WiFi queries
            elif any(keyword in user_lower for keyword in ["á€á€­á€¯á€„á€ºá€–á€­á€¯á€„á€º", "wifi", "á€¡á€„á€ºá€á€¬á€”á€€á€º", "internet"]):
                return """á€¡á€á€™á€²á€· WiFi á€á€”á€ºá€†á€±á€¬á€„á€ºá€™á€¾á€¯á€›á€¾á€­á€•á€«á€á€šá€ºá‹

WiFi á€…á€€á€¬á€¸á€á€¾á€€á€ºá€€á€­á€¯ á€…á€¬á€¸á€•á€½á€²á€á€„á€ºá€á€”á€ºá€‘á€™á€ºá€¸á€™á€»á€¬á€¸á€‘á€¶ á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹

á€¡á€„á€ºá€á€¬á€”á€€á€ºá€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€›á€¾á€­á€•á€«á€€ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"""
            
            # General fallback for other queries
            else:
                return "á€’á€®á€¡á€€á€¼á€±á€¬á€„á€ºá€¸á€¡á€›á€¬á€”á€²á€· á€•á€á€ºá€á€€á€ºá€•á€¼á€®á€¸ á€á€±á€á€»á€¬ á€™á€á€­á€›á€¾á€­á€œá€­á€¯á€· á€á€±á€¬á€„á€ºá€¸á€•á€”á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€¡á€á€±á€¸á€…á€­á€á€º á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€º á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€”á€¬á€¸á€œá€Šá€ºá€•á€±á€¸á€á€²á€·á€¡á€á€½á€€á€º á€€á€»á€±á€¸á€‡á€°á€¸ á€¡á€™á€»á€¬á€¸á€€á€¼á€®á€¸ á€á€„á€ºá€•á€«á€á€šá€ºá‹"
            
        except Exception as e:
            logger.error("enhanced_burmese_fallback_failed", error=str(e))
            return "á€’á€®á€¡á€€á€¼á€±á€¬á€„á€ºá€¸á€¡á€›á€¬á€”á€²á€· á€•á€á€ºá€á€€á€ºá€•á€¼á€®á€¸ á€á€±á€á€»á€¬ á€™á€á€­á€›á€¾á€­á€œá€­á€¯á€· á€á€±á€¬á€„á€ºá€¸á€•á€”á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€¡á€á€±á€¸á€…á€­á€á€º á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€º á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€”á€¬á€¸á€œá€Šá€ºá€•á€±á€¸á€á€²á€·á€¡á€á€½á€€á€º á€€á€»á€±á€¸á€‡á€°á€¸ á€¡á€™á€»á€¬á€¸á€€á€¼á€®á€¸ á€á€„á€ºá€•á€«á€á€šá€ºá‹"
    
    async def _handle_burmese_menu_response(self, user_message: str, rag_results: List[Dict[str, Any]], relevance_score: float) -> str:
        """
        Handle Burmese menu-specific responses using LLM - NO PATTERN MATCHING
        """
        try:
            # Use LLM to generate menu response based on RAG results
            context = self._prepare_rag_context(rag_results)
            prompt = self._create_enhanced_menu_prompt(user_message, context)
            
            from langchain_core.messages import HumanMessage
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return response.content.strip()
                
        except Exception as e:
            logger.error("burmese_menu_response_handling_failed", error=str(e))
            return "á€™á€®á€”á€°á€¸á€”á€²á€·á€•á€á€ºá€á€€á€ºá€á€²á€· á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ á€›á€šá€°á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€¯ á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€šá€ºá‹"
    
    async def _generate_categories_response(self) -> str:
        """Generate response showing menu categories (extracted from burmese_customer_services_handler.py)"""
        try:
            # Get categories from vector search
            from src.services.vector_search_service import get_vector_search_service
            vector_service = get_vector_search_service()
            categories = await vector_service.get_menu_categories("my")
            
            if not categories:
                return "á€™á€®á€”á€°á€¸á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€›á€šá€°á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€¯ á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€šá€ºá‹"
            
            # Format natural response
            response = "á€€á€»á€”á€±á€¬á€ºá€á€­á€¯á€·á€›á€²á€· á€™á€®á€”á€°á€¸á€™á€¾á€¬ á€’á€®á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€á€½á€± á€›á€¾á€­á€•á€«á€á€šá€º:\n\n"
            for category in categories:
                display_name = category["display_name"]
                response += f"â€¢ **{display_name}**\n"
            response += "\ná€˜á€šá€ºá€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€€á€­á€¯ á€€á€¼á€Šá€·á€ºá€á€»á€„á€ºá€•á€«á€á€œá€²?"
            
            return response
            
        except Exception as e:
            logger.error("categories_response_generation_failed", error=str(e))
            return "á€™á€®á€”á€°á€¸á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€›á€šá€°á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€¯ á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€šá€ºá‹"
    
    async def _generate_category_items_response(self, category: str) -> str:
        """Generate response showing items from a specific category (extracted from burmese_customer_services_handler.py)"""
        try:
            # Get items from vector search
            from src.services.vector_search_service import get_vector_search_service
            vector_service = get_vector_search_service()
            items = await vector_service.get_category_items(category, "my", limit=12)
            
            if not items:
                return f"'{category}' á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€™á€¾á€¬ á€¡á€…á€¬á€¸á€¡á€…á€¬á€™á€»á€¬á€¸ á€™á€á€½á€±á€·á€›á€¾á€­á€•á€«á€˜á€°á€¸á‹"
            
            # Format response with names and prices
            category_name = vector_service._get_category_display_name(category, "my")
            response = f"**{category_name}** á€¡á€…á€¬á€¸á€¡á€…á€¬á€á€½á€±á€•á€«:\n\n"
            
            for i, item in enumerate(items, 1):
                name = item.get("name", "N/A")
                myanmar_name = item.get("name_other", "")
                price = item.get("price", "N/A")
                currency = item.get("currency", "MMK")
                
                if myanmar_name:
                    response += f"{i}. **{name}** ({myanmar_name})\n"
                    response += f"   ğŸ’° {price:,} {currency}\n\n"
                else:
                    response += f"{i}. **{name}**\n"
                    response += f"   ğŸ’° {price:,} {currency}\n\n"
            
            response += "á€˜á€šá€ºá€¡á€…á€¬á€¸á€¡á€…á€¬á€€á€­á€¯ á€•á€­á€¯á€™á€­á€¯á€á€­á€á€»á€„á€ºá€•á€«á€á€œá€²?"
            
            return response
            
        except Exception as e:
            logger.error("category_items_response_generation_failed", error=str(e))
            return f"'{category}' á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€™á€¾á€¬ á€¡á€…á€¬á€¸á€¡á€…á€¬á€™á€»á€¬á€¸á€€á€­á€¯ á€›á€šá€°á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€¯ á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€šá€ºá‹"
    
    async def _generate_item_details_response(self, item_name: str) -> str:
        """Generate response with detailed information about a specific item (extracted from burmese_customer_services_handler.py)"""
        try:
            # Get item details from vector search
            from src.services.vector_search_service import get_vector_search_service
            vector_service = get_vector_search_service()
            item = await vector_service.get_item_details(item_name, "my")
            
            if not item:
                return f"'{item_name}' á€¡á€…á€¬á€¸á€¡á€…á€¬á€€á€­á€¯ á€™á€á€½á€±á€·á€›á€¾á€­á€•á€«á€˜á€°á€¸á‹"
            
            # Check if this is a clarification request
            if item.get("type") == "clarification_needed":
                return item["message"]
            
            # Check if we have a confidence score
            if not item.get("similarity_score"):
                return f"'{item_name}' á€¡á€…á€¬á€¸á€¡á€…á€¬á€”á€²á€·á€•á€á€ºá€á€€á€ºá€á€²á€· á€¡á€á€±á€¸á€…á€­á€á€ºá€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ á€›á€šá€°á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€¯ á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€šá€ºá‹"
            
            # Format natural conversational response
            response = f"**{item['name']}** á€¡á€€á€¼á€±á€¬á€„á€ºá€¸ á€•á€¼á€±á€¬á€•á€¼á€•á€±á€¸á€•á€«á€›á€…á€±á‹\n\n"
            response += f"á€ˆá€±á€¸á€”á€¾á€¯á€”á€ºá€¸á€€á€á€±á€¬á€· {item['price']:,} {item['currency']} á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹\n"
            response += f"{item['description']}\n\n"
            response += f"á€•á€¼á€„á€ºá€†á€„á€ºá€á€»á€­á€”á€ºá€€ {item['preparation_time']} á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹\n"
            response += f"á€¡á€…á€•á€ºá€¡á€†á€„á€·á€ºá€€ {item['spice_level']}/4 á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹\n"
            
            if item.get("ingredients"):
                response += f"\ná€•á€«á€á€„á€ºá€•á€…á€¹á€…á€Šá€ºá€¸á€á€½á€±á€€á€á€±á€¬á€· {', '.join(item['ingredients'])} á€á€­á€¯á€· á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹\n"
            
            if item.get("allergens"):
                response += f"\ná€“á€¬á€á€ºá€™á€á€Šá€·á€ºá€™á€¾á€¯á€›á€¾á€­á€á€²á€· á€•á€«á€á€„á€ºá€•á€…á€¹á€…á€Šá€ºá€¸á€á€½á€±á€€á€á€±á€¬á€· {', '.join(item['allergens'])} á€á€­á€¯á€· á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹\n"
            
            # Add suggested alternatives if available
            if item.get('suggested_alternatives'):
                response += f"\ná€¡á€œá€¬á€¸á€á€° á€¡á€…á€¬á€¸á€¡á€á€±á€¬á€€á€ºá€™á€»á€¬á€¸: {', '.join(item['suggested_alternatives'])}"
            
            response += f"\ná€•á€¯á€¶á€€á€­á€¯ á€€á€¼á€Šá€·á€ºá€á€»á€„á€ºá€•á€«á€á€œá€¬á€¸?"
            
            return response
            
        except Exception as e:
            logger.error("item_details_response_generation_failed", error=str(e))
            return f"'{item_name}' á€¡á€…á€¬á€¸á€¡á€…á€¬á€”á€²á€·á€•á€á€ºá€á€€á€ºá€á€²á€· á€¡á€á€±á€¸á€…á€­á€á€ºá€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ á€›á€šá€°á€›á€¬á€á€½á€„á€º á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€¯ á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€šá€ºá‹"
    


    def _create_enhanced_menu_prompt(self, user_message: str, context: str) -> str:
        """Create enhanced menu response prompt that uses actual Burmese data"""
        return f"""
You are a helpful restaurant chatbot assistant for Cafe Pentagon. Generate a response in Burmese based on the user's question about the menu.

USER QUESTION: {user_message}

ACTUAL MENU DATA FROM DATABASE (Burmese content included):
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Use ONLY the actual menu data provided above
- If the data shows Burmese names (myanmar_name), use them
- If the data shows Burmese descriptions (description_mm), use them
- Do NOT translate or invent any information not present in the data
- If the data shows specific items with prices, describe them accurately
- Be friendly and helpful
- Keep the response conversational and natural
- If the data is incomplete, mention that more details can be found by calling +959979732781

IMPORTANT: Use the Burmese content directly from the data. Do not translate or invent information.

RESPONSE:"""

    def _create_enhanced_faq_prompt(self, user_message: str, context: str) -> str:
        """Create enhanced FAQ response prompt that uses actual Burmese data"""
        return f"""
You are a helpful restaurant chatbot assistant for Cafe Pentagon. Generate a response in Burmese based on the user's FAQ question.

USER QUESTION: {user_message}

ACTUAL FAQ DATA FROM DATABASE (Burmese content included):
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Use ONLY the actual FAQ data provided above
- If the data shows Burmese questions (question_mm), use them
- If the data shows Burmese answers (answer_mm), use them
- Do NOT translate or invent any information not present in the data
- If the data shows specific answers, provide them accurately
- If the data shows opening hours, location, or other details, use them exactly
- Be friendly and helpful
- Keep the response conversational and natural
- If the data is incomplete, suggest calling +959979732781 for more details

IMPORTANT: Use the Burmese content directly from the data. Do not translate or invent information.

RESPONSE:"""

    def _create_enhanced_job_prompt(self, user_message: str, context: str) -> str:
        """Create enhanced job response prompt that uses actual Burmese data"""
        return f"""
You are a helpful restaurant chatbot assistant for Cafe Pentagon. Generate a response in Burmese about job opportunities.

USER QUESTION: {user_message}

ACTUAL JOB DATA FROM DATABASE (Burmese content included):
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Use ONLY the actual job data provided above
- If the data shows Burmese titles (title_mm), use them
- If the data shows Burmese descriptions (description_mm), use them
- Do NOT translate or invent any information not present in the data
- If the data shows available positions, describe them accurately
- If the data shows application process, include it
- Be friendly and professional
- Keep the response helpful and informative

IMPORTANT: Use the Burmese content directly from the data. Do not translate or invent information.

RESPONSE:"""

    def _create_enhanced_general_prompt(self, user_message: str, context: str) -> str:
        """Create enhanced general response prompt that uses actual Burmese data"""
        return f"""
You are a helpful restaurant chatbot assistant for Cafe Pentagon. Generate a response in Burmese based on the user's question.

USER QUESTION: {user_message}

ACTUAL DATA FROM DATABASE (Burmese content included):
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Use ONLY the actual data provided above
- If the data shows Burmese content (title_mm, description_mm, etc.), use it directly
- Do NOT translate or invent any information not present in the data
- Provide relevant information based on the data
- Be friendly and helpful
- Keep the response conversational and natural
- If information is incomplete, suggest calling +959979732781

IMPORTANT: Use the Burmese content directly from the data. Do not translate or invent information.

RESPONSE:"""

    async def _generate_greeting_response(self, language: str, cultural_context: Dict[str, Any]) -> str:
        """Generate greeting response with cultural context awareness"""
        formality_level = cultural_context.get("formality_level", "casual")
        uses_honorifics = cultural_context.get("uses_honorifics", False)
        
        if language == "my":
            if formality_level == "very_formal" or uses_honorifics:
                return "á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€« á€á€„á€ºá€—á€»á€¬! á€€á€»á€”á€±á€¬á€ºá€á€­á€¯á€· Cafe Pentagon á€™á€¾á€¬ á€€á€¼á€­á€¯á€†á€­á€¯á€•á€«á€á€šá€ºá‹ á€˜á€¬á€€á€°á€Šá€®á€•á€±á€¸á€›á€™á€œá€² á€á€„á€ºá€—á€»á€¬?"
            elif formality_level == "formal":
                return "á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«! á€€á€»á€”á€±á€¬á€ºá€á€­á€¯á€· Cafe Pentagon á€™á€¾á€¬ á€€á€¼á€­á€¯á€†á€­á€¯á€•á€«á€á€šá€ºá‹ á€˜á€¬á€€á€°á€Šá€®á€•á€±á€¸á€›á€™á€œá€²?"
            else:
                return "á€™á€„á€ºá€¹á€‚á€œá€¬! á€€á€»á€”á€±á€¬á€ºá€á€­á€¯á€· Cafe Pentagon á€™á€¾á€¬ á€€á€¼á€­á€¯á€†á€­á€¯á€•á€«á€á€šá€ºá‹ á€˜á€¬á€€á€°á€Šá€®á€•á€±á€¸á€›á€™á€œá€²?"
        else:
            return "Hello! Welcome to Cafe Pentagon. How can I help you today?"
    
    async def _generate_goodbye_response(self, language: str, cultural_context: Dict[str, Any]) -> str:
        """Generate goodbye response with cultural context awareness"""
        formality_level = cultural_context.get("formality_level", "casual")
        uses_honorifics = cultural_context.get("uses_honorifics", False)
        
        if language == "my":
            if formality_level == "very_formal" or uses_honorifics:
                return "á€€á€»á€±á€¸á€‡á€°á€¸á€á€„á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬! á€¡á€á€¼á€¬á€¸ á€á€­á€œá€­á€¯á€á€¬ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€«á€”á€±á€¬á€º á€á€„á€ºá€—á€»á€¬á‹"
            elif formality_level == "formal":
                return "á€€á€»á€±á€¸á€‡á€°á€¸á€á€„á€ºá€•á€«á€á€šá€º! á€¡á€á€¼á€¬á€¸ á€á€­á€œá€­á€¯á€á€¬ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€«á€”á€±á€¬á€ºá‹"
            else:
                return "á€€á€»á€±á€¸á€‡á€°á€¸á€•á€«! á€¡á€á€¼á€¬á€¸ á€á€­á€œá€­á€¯á€á€¬ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€«á€”á€±á€¬á€ºá‹"
        else:
            return "Thank you! Feel free to ask if you need anything else."
    
    async def _generate_escalation_response(self, language: str, escalation_reason: Optional[str]) -> str:
        """Generate escalation response with specific reason"""
        if language == "my":
            if escalation_reason and "human assistance" in escalation_reason.lower():
                return "á€á€¬á€á€”á€ºá€›á€¾á€­ á€á€”á€ºá€‘á€™á€ºá€¸á€á€…á€ºá€šá€±á€¬á€€á€º á€œá€¬á€•á€¼á€®á€¸ á€€á€°á€Šá€®á€•á€±á€¸á€•á€«á€œá€­á€™á€·á€ºá€™á€šá€º..áŠ á€á€á€…á€±á€¬á€„á€·á€ºá€•á€±á€¸á€•á€« á€á€„á€ºá€—á€»á€¬.."
            elif escalation_reason:
                return f"á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á á€á€á€…á€±á€¬á€„á€·á€ºá€•á€±á€¸á€•á€« á€á€„á€ºá€—á€»á€¬...á‹ {escalation_reason} á€¡á€á€½á€€á€º á€á€€á€ºá€†á€­á€¯á€„á€ºá€›á€¬ á€á€”á€ºá€‘á€™á€ºá€¸á€€ á€€á€°á€Šá€®á€•á€±á€¸á€•á€«á€œá€­á€™á€·á€ºá€™á€šá€ºá‹"
            else:
                return "á€á€¬á€á€”á€ºá€›á€¾á€­ á€á€”á€ºá€‘á€™á€ºá€¸á€á€…á€ºá€šá€±á€¬á€€á€º á€œá€¬á€•á€¼á€®á€¸ á€€á€°á€Šá€®á€•á€±á€¸á€•á€«á€œá€­á€™á€·á€ºá€™á€šá€º..áŠ á€á€á€…á€±á€¬á€„á€·á€ºá€•á€±á€¸á€•á€« á€á€„á€ºá€—á€»á€¬.."
        else:
            if escalation_reason and "human assistance" in escalation_reason.lower():
                return "The responsible staff will be here and assist to you. could you wait a moment"
            elif escalation_reason:
                return f"Please wait while I connect you to a human staff member who can help you with {escalation_reason.lower()}."
            else:
                return "The responsible staff will be here and assist to you. could you wait a moment"
    
    async def _generate_fallback_response(self, user_message: str, language: str, intent: str, cultural_context: Dict[str, Any]) -> str:
        """Generate fallback response when no relevant information is found"""
        formality_level = cultural_context.get("formality_level", "casual")
        uses_honorifics = cultural_context.get("uses_honorifics", False)
        
        if language == "my":
            if formality_level == "very_formal" or uses_honorifics:
                return "á€’á€®á€¡á€€á€¼á€±á€¬á€„á€ºá€¸á€¡á€›á€¬á€”á€²á€· á€•á€á€ºá€á€€á€ºá€•á€¼á€®á€¸ á€á€±á€á€»á€¬ á€™á€á€­á€›á€¾á€­á€œá€­á€¯á€· á€á€±á€¬á€„á€ºá€¸á€•á€”á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€¡á€á€±á€¸á€…á€­á€á€º á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€º á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€”á€¬á€¸á€œá€Šá€ºá€•á€±á€¸á€á€²á€·á€¡á€á€½á€€á€º á€€á€»á€±á€¸á€‡á€°á€¸ á€¡á€™á€»á€¬á€¸á€€á€¼á€®á€¸ á€á€„á€ºá€•á€«á€á€šá€ºá‹"
            elif formality_level == "formal":
                return "á€’á€®á€¡á€€á€¼á€±á€¬á€„á€ºá€¸á€¡á€›á€¬á€”á€²á€· á€•á€á€ºá€á€€á€ºá€•á€¼á€®á€¸ á€á€±á€á€»á€¬ á€™á€á€­á€›á€¾á€­á€œá€­á€¯á€· á€á€±á€¬á€„á€ºá€¸á€•á€”á€ºá€•á€«á€á€šá€ºá‹ á€¡á€á€±á€¸á€…á€­á€á€º á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€º á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"
            else:
                return "á€’á€®á€¡á€€á€¼á€±á€¬á€„á€ºá€¸á€¡á€›á€¬á€”á€²á€· á€•á€á€ºá€á€€á€ºá€•á€¼á€®á€¸ á€á€±á€á€»á€¬ á€™á€á€­á€›á€¾á€­á€œá€­á€¯á€· á€á€±á€¬á€„á€ºá€¸á€•á€”á€ºá€•á€«á€á€šá€ºá‹ á€¡á€á€±á€¸á€…á€­á€á€º á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€€á€­á€¯ +959979732781 á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€º á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹"
        else:
            return "I'm sorry, I don't have specific information about that. Please call +959979732781 for detailed assistance. Thank you for your understanding."
    
    async def _generate_contextual_response(self, user_message: str, language: str, intent: str, rag_results: List[Dict[str, Any]], cultural_context: Dict[str, Any]) -> str:
        """Generate contextual response based on RAG results with cultural context"""
        
        # Prepare context from RAG results
        context = self._prepare_rag_context(rag_results)
        
        # Create prompt based on intent
        if intent == "menu_browse":
            prompt = self._create_menu_response_prompt(user_message, context, language)
        elif intent == "faq":
            prompt = self._create_faq_response_prompt(user_message, context, language)
        elif intent in ["job_application", "jobs"]:
            prompt = self._create_job_response_prompt(user_message, context, language)
        else:
            prompt = self._create_general_response_prompt(user_message, context, language)
        
        try:
            # Generate response using LLM
            from langchain_core.messages import HumanMessage
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return response.content.strip()
            
        except Exception as e:
            logger.error("llm_response_generation_failed", error=str(e))
            return await self._generate_fallback_response(user_message, language, intent, cultural_context)
    
    def _prepare_rag_context(self, rag_results: List[Dict[str, Any]]) -> str:
        """Prepare context string from RAG results with detailed information"""
        if not rag_results:
            return ""
        
        context_parts = []
        for i, result in enumerate(rag_results[:5], 1):  # Top 5 results
            content = result.get("content", "")
            metadata = result.get("metadata", {})
            score = result.get("score", 0.0)
            source = result.get("source", "")
            
            # Add detailed information
            context_parts.append(f"=== Result {i} (Score: {score:.3f}, Source: {source}) ===")
            context_parts.append(f"Content: {content}")
            
            # Add metadata details if available
            if metadata:
                if "title" in metadata:
                    context_parts.append(f"Title: {metadata['title']}")
                if "category" in metadata:
                    context_parts.append(f"Category: {metadata['category']}")
                if "price" in metadata:
                    context_parts.append(f"Price: {metadata['price']}")
                if "description" in metadata:
                    context_parts.append(f"Description: {metadata['description']}")
                if "name" in metadata:
                    context_parts.append(f"Name: {metadata['name']}")
                if "myanmar_name" in metadata:
                    context_parts.append(f"Myanmar Name: {metadata['myanmar_name']}")
                # Add Burmese-specific fields
                if "question_mm" in metadata:
                    context_parts.append(f"Question (Myanmar): {metadata['question_mm']}")
                if "answer_mm" in metadata:
                    context_parts.append(f"Answer (Myanmar): {metadata['answer_mm']}")
                if "description_mm" in metadata:
                    context_parts.append(f"Description (Myanmar): {metadata['description_mm']}")
                if "title_mm" in metadata:
                    context_parts.append(f"Title (Myanmar): {metadata['title_mm']}")
            
            context_parts.append("")  # Empty line for separation
        
        return "\n".join(context_parts)
    
    def _create_menu_response_prompt(self, user_message: str, context: str, language: str) -> str:
        """Create prompt for menu-related responses"""
        if language == "my":
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response in Burmese based on the user's question about the menu.

USER QUESTION: {user_message}

MENU INFORMATION:
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Be friendly and helpful
- Provide relevant menu information
- If specific items are mentioned, include details like price, description, ingredients
- If no specific items are mentioned, suggest popular items or categories
- Keep the response conversational and natural

RESPONSE:"""
        else:
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response based on the user's question about the menu.

USER QUESTION: {user_message}

MENU INFORMATION:
{context}

INSTRUCTIONS:
- Be friendly and helpful
- Provide relevant menu information
- If specific items are mentioned, include details like price, description, ingredients
- If no specific items are mentioned, suggest popular items or categories
- Keep the response conversational and natural

RESPONSE:"""
    
    def _create_faq_response_prompt(self, user_message: str, context: str, language: str) -> str:
        """Create prompt for FAQ-related responses"""
        if language == "my":
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response in Burmese based on the user's FAQ question.

USER QUESTION: {user_message}

FAQ INFORMATION:
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Be friendly and helpful
- Provide clear and accurate information
- If information is incomplete, suggest calling +959979732781
- Keep the response conversational and natural

RESPONSE:"""
        else:
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response based on the user's FAQ question.

USER QUESTION: {user_message}

FAQ INFORMATION:
{context}

INSTRUCTIONS:
- Be friendly and helpful
- Provide clear and accurate information
- If information is incomplete, suggest calling +959979732781
- Keep the response conversational and natural

RESPONSE:"""
    
    def _create_job_response_prompt(self, user_message: str, context: str, language: str) -> str:
        """Create prompt for job-related responses"""
        if language == "my":
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response in Burmese about job opportunities.

USER QUESTION: {user_message}

JOB INFORMATION:
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Be friendly and professional
- Provide information about available positions
- Include application process if mentioned
- Encourage qualified candidates to apply

RESPONSE:"""
        else:
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response about job opportunities.

USER QUESTION: {user_message}

JOB INFORMATION:
{context}

INSTRUCTIONS:
- Be friendly and professional
- Provide information about available positions
- Include application process if mentioned
- Encourage qualified candidates to apply

RESPONSE:"""
    
    def _create_general_response_prompt(self, user_message: str, context: str, language: str) -> str:
        """Create prompt for general responses"""
        if language == "my":
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response in Burmese based on the user's question.

USER QUESTION: {user_message}

RELEVANT INFORMATION:
{context}

INSTRUCTIONS:
- Respond in Burmese language
- Be friendly and helpful
- Provide relevant information
- If information is incomplete, suggest calling +959979732781
- Keep the response conversational and natural

RESPONSE:"""
        else:
            return f"""
You are a helpful restaurant chatbot assistant. Generate a response based on the user's question.

USER QUESTION: {user_message}

RELEVANT INFORMATION:
{context}

INSTRUCTIONS:
- Be friendly and helpful
- Provide relevant information
- If information is incomplete, suggest calling +959979732781
- Keep the response conversational and natural

RESPONSE:"""
    
    def _assess_response_quality(self, response: str, intent_confidence: float, decision_confidence: float) -> str:
        """Assess the quality of the generated response based on confidence scores"""
        # Calculate overall confidence
        overall_confidence = (intent_confidence + decision_confidence) / 2
        
        if overall_confidence > 0.7:
            return "high"
        elif overall_confidence > 0.4:
            return "medium"
        else:
            return "low" 

 

    async def _generate_direct_response(self, user_message: str, language: str, intent: str, cultural_context: Dict[str, Any]) -> str:
        """Generate direct response for non-search intents"""
        formality_level = cultural_context.get("formality_level", "casual")
        uses_honorifics = cultural_context.get("uses_honorifics", False)
        
        if language == "my":
            if intent == "greeting":
                return await self._generate_greeting_response(language, cultural_context)
            elif intent == "goodbye":
                return await self._generate_goodbye_response(language, cultural_context)
            else:
                # Generic direct response
                if formality_level == "very_formal" or uses_honorifics:
                    return "á€”á€¬á€¸á€œá€Šá€ºá€•á€±á€¸á€á€²á€·á€¡á€á€½á€€á€º á€€á€»á€±á€¸á€‡á€°á€¸á€á€„á€ºá€•á€«á€á€šá€º á€á€„á€ºá€—á€»á€¬á‹ á€¡á€á€¼á€¬á€¸ á€á€­á€œá€­á€¯á€á€¬ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€«á€”á€±á€¬á€º á€á€„á€ºá€—á€»á€¬á‹"
                elif formality_level == "formal":
                    return "á€”á€¬á€¸á€œá€Šá€ºá€•á€±á€¸á€á€²á€·á€¡á€á€½á€€á€º á€€á€»á€±á€¸á€‡á€°á€¸á€á€„á€ºá€•á€«á€á€šá€ºá‹ á€¡á€á€¼á€¬á€¸ á€á€­á€œá€­á€¯á€á€¬ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€«á€”á€±á€¬á€ºá‹"
                else:
                    return "á€€á€»á€±á€¸á€‡á€°á€¸á€•á€«á‹ á€¡á€á€¼á€¬á€¸ á€á€­á€œá€­á€¯á€á€¬ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€«á€”á€±á€¬á€ºá‹"
        else:
            if intent == "greeting":
                return await self._generate_greeting_response(language, cultural_context)
            elif intent == "goodbye":
                return await self._generate_goodbye_response(language, cultural_context)
            else:
                return "Thank you for your message. Feel free to ask if you need anything else." 